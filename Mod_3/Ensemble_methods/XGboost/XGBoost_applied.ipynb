{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running an XGboosted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the appropriate packages\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and split data to be used in the models\n",
    "titanic = pd.read_csv('cleaned_titanic.csv', index_col='PassengerId')\n",
    "\n",
    "# Create matrix of features\n",
    "X = titanic.drop('Survived', axis = 1) # grabs everything else but 'Survived'\n",
    "\n",
    "# Create target variable\n",
    "y = titanic['Survived'] # y is the column we're trying to predict\n",
    "\n",
    "# Create a list of the features being used in the \n",
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost's hyperparameters\n",
    "\n",
    "At this point, before building the model, you should be aware of the tuning parameters that XGBoost provides. Well, there are a plethora of tuning parameters for tree-based learners in XGBoost and you can read all about them [here](https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters). But the most common ones that you should know are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall parameters have been divided into 3 categories by XGBoost authors:\n",
    "\n",
    "- **General Parameters:** Guide the overall functioning\n",
    "- **Booster Parameters:** Guide the individual booster (tree/regression) at each step\n",
    "- **Learning Task Parameters:** Guide the optimization performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Parameters\n",
    "These define the overall functionality of XGBoost.\n",
    "\n",
    "- **booster** [default=gbtree]\n",
    "Select the type of model to run at each iteration. It has 2 options:\n",
    "    - gbtree: tree-based models\n",
    "    - gblinear: linear models\n",
    "    \n",
    "- **silent** [default=0]:\n",
    "Silent mode is activated is set to 1, i.e. no running messages will be printed. It’s generally good to keep it 0 as the messages might help in understanding the model.\n",
    "\n",
    "- **nthread**  [default to maximum number of threads available if not set]\n",
    "This is used for parallel processing and number of cores in the system should be entered. If you wish to run on all cores, value should not be entered and algorithm will detect automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booster Parameters\n",
    "Though there are 2 types of boosters, we’ll consider only tree booster here because it always outperforms the linear booster and thus the later is rarely used.\n",
    "\n",
    "- **eta [default=0.3]**\n",
    "    - Analogous to learning rate in GBM\n",
    "    - Makes the model more robust by shrinking the weights on each step\n",
    "    - Typical final values to be used: 0.01-0.2\n",
    "- **min_child_weight [default=1]**\n",
    "    - Defines the minimum sum of weights of all observations required in a child.\n",
    "    - This is similar to min_child_leaf in GBM but not exactly. This refers to min “sum of weights” of observations while GBM has min “number of observations”.\n",
    "    - Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "    - Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "- **max_depth [default=6]**\n",
    "    - The maximum depth of a tree, same as GBM.\n",
    "    - Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "    - Should be tuned using CV.\n",
    "    - Typical values: 3-10\n",
    "- **max_leaf_nodes**\n",
    "    - The maximum number of terminal nodes or leaves in a tree.\n",
    "    - Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves.\n",
    "    - If this is defined, GBM will ignore max_depth.\n",
    "- **gamma [default=0]**\n",
    "    - A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split.\n",
    "    - Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
    "- **max_delta_step [default=0]**\n",
    "    - In maximum delta step we allow each tree’s weight estimation to be. If the value is set to 0, it means there is no constraint. If it is set to a positive value, it can help making the update step more conservative.\n",
    "    - Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced.\n",
    "    - This is generally not used but you can explore further if you wish.\n",
    "- **subsample [default=1]**\n",
    "    - Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.\n",
    "    - Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.\n",
    "    - Typical values: 0.5-1\n",
    "- **colsample_bytree [default=1]**\n",
    "    - Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.\n",
    "    - Typical values: 0.5-1\n",
    "- **colsample_bylevel [default=1]**\n",
    "    - Denotes the subsample ratio of columns for each split, in each level.\n",
    "    - I don’t use this often because subsample and colsample_bytree will do the job for you. but you can explore further if you feel so.\n",
    "- **lambda [default=1]**\n",
    "    - L2 regularization term on weights (analogous to Ridge regression)\n",
    "    - This used to handle the regularization part of XGBoost. Though many data scientists don’t use it often, it should be explored to reduce overfitting.\n",
    "- **alpha [default=0]**\n",
    "    - L1 regularization term on weight (analogous to Lasso regression)\n",
    "    - Can be used in case of very high dimensionality so that the algorithm runs faster when implemented\n",
    "- **scale_pos_weight [default=1]**\n",
    "    - A value greater than 0 should be used in case of high class imbalance as it helps in faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Task Parameters\n",
    "\n",
    "These parameters are used to define the optimization objective the metric to be calculated at each step.\n",
    "\n",
    "- **objective [default=reg:linear]**\n",
    "    - This defines the loss function to be minimized. Mostly used values are:\n",
    "        - binary:logistic –logistic regression for binary classification, returns predicted probability (not class)\n",
    "        - multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities)\n",
    "                - you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "        - multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "- **eval_metric [ default according to objective ]**\n",
    "    - The metric to be used for validation data.\n",
    "    - The default values are rmse for regression and error for classification.\n",
    "    - Typical values are:\n",
    "            - rmse – root mean square error\n",
    "            - mae – mean absolute error\n",
    "            - logloss – negative log-likelihood\n",
    "            - error – Binary classification error rate (0.5 threshold)\n",
    "            - merror – Multiclass classification error rate\n",
    "            - mlogloss – Multiclass logloss\n",
    "            - auc: Area under the curve\n",
    "- **seed [default=0]**\n",
    "    - The random number seed.\n",
    "    - Can be used for generating reproducible results and also for parameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning with Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38245219347581555"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                           colsample_bytree = 0.3, \n",
    "                           subsample = 0.5,\n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 4, \n",
    "                           alpha = 1, \n",
    "                           #scale_pos_weight= titanic['Survived'].mean(),\n",
    "                           n_estimators = 10000,\n",
    "                          silent= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=1, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=10000, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=1, reg_lambda=1, scale_pos_weight=1, silent=1,\n",
       "              subsample=0.5, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784753\n",
      "F1: 0.675676\n"
     ]
    }
   ],
   "source": [
    "preds = xg_clf.predict(X_test)\n",
    "\n",
    "\n",
    "test_f1 = f1_score(y_test, preds)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold Cross Validation using XGBoost\n",
    "In order to build more robust models, it is common to do a k-fold cross validation where all the entries in the original training dataset are used for both training as well as validation. XGBoost supports k-fold cross validation via the cv() method. All you have to do is specify the nfolds parameter, which is the number of cross validation sets you want to build. Also, it supports many other parameters (check out this link) like:\n",
    "\n",
    "- **num_boost_round**: denotes the number of trees you build (analogous to n_estimators)\n",
    "- **metrics:** tells the evaluation metrics to be watched during CV\n",
    "- **as_pandas**: to return the results in a pandas DataFrame.\n",
    "- **early_stopping_rounds: finishes training of the model early if the hold-out metric (\"rmse\" in our case) does not improve for a given number of rounds.\n",
    "- **seed**: for reproducibility of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running your model, you will convert the dataset into an optimized data structure called Dmatrix that XGBoost supports and gives it acclaimed performance and efficiency gains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.DMatrix at 0x7fb53463fe10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\":\"binary:logistic\",\n",
    "          'colsample_bytree': 0.3,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 3, \n",
    "          'alpha': 1}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, \n",
    "                    params=params, \n",
    "                    nfold=5,\n",
    "                    num_boost_round=500,\n",
    "                    early_stopping_rounds=5,\n",
    "                    metrics=\"logloss\", \n",
    "                    as_pandas=True, \n",
    "                    seed=123)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.659772</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.660168</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.639740</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>0.640184</td>\n",
       "      <td>0.010529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.627790</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.629019</td>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.614868</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.616503</td>\n",
       "      <td>0.015193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599252</td>\n",
       "      <td>0.010672</td>\n",
       "      <td>0.601503</td>\n",
       "      <td>0.014880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.372616</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>0.434313</td>\n",
       "      <td>0.038028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.371920</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.434456</td>\n",
       "      <td>0.038454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.371195</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.434110</td>\n",
       "      <td>0.038592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.370798</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.434108</td>\n",
       "      <td>0.038613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.370584</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.433982</td>\n",
       "      <td>0.038632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-logloss-mean  train-logloss-std  test-logloss-mean  \\\n",
       "0              0.659772           0.000848           0.660168   \n",
       "1              0.639740           0.006761           0.640184   \n",
       "2              0.627790           0.006071           0.629019   \n",
       "3              0.614868           0.010607           0.616503   \n",
       "4              0.599252           0.010672           0.601503   \n",
       "..                  ...                ...                ...   \n",
       "127            0.372616           0.009112           0.434313   \n",
       "128            0.371920           0.009004           0.434456   \n",
       "129            0.371195           0.009250           0.434110   \n",
       "130            0.370798           0.009382           0.434108   \n",
       "131            0.370584           0.009246           0.433982   \n",
       "\n",
       "     test-logloss-std  \n",
       "0            0.001478  \n",
       "1            0.010529  \n",
       "2            0.010380  \n",
       "3            0.015193  \n",
       "4            0.014880  \n",
       "..                ...  \n",
       "127          0.038028  \n",
       "128          0.038454  \n",
       "129          0.038592  \n",
       "130          0.038613  \n",
       "131          0.038632  \n",
       "\n",
       "[132 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xg_clf)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors, target, useTrainCV=True, cv_folds=5, early_stopping_rounds=5):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "\n",
    "    return alg\n",
    "#     feat_imp = pd.Series(alg.get_booster().get_fscore())\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.concat([X_train, y_train], axis=1)\n",
    "target = 'Survived'\n",
    "IDcol = 'PassengerId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>youngin</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass   Age  SibSp  Parch     Fare  youngin  male  Q  S  \\\n",
       "PassengerId                                                             \n",
       "740               3  24.0      0      0   7.8958        0     1  0  1   \n",
       "148               3   9.0      2      2  34.3750        1     0  0  1   \n",
       "876               3  15.0      0      0   7.2250        0     0  0  0   \n",
       "641               3  20.0      0      0   7.8542        0     1  0  1   \n",
       "885               3  25.0      0      0   7.0500        0     1  0  1   \n",
       "\n",
       "             Survived  \n",
       "PassengerId            \n",
       "740                 0  \n",
       "148                 0  \n",
       "876                 1  \n",
       "641                 0  \n",
       "885                 0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.8919\n",
      "AUC Score (Train): 0.939281\n"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "xgb1 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.6,\n",
    " colsample_bytree=0.3,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "alg = modelfit(xgb1, train, predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.802691\n",
      "F1: 0.702703\n"
     ]
    }
   ],
   "source": [
    "preds = alg.predict(X_test)\n",
    "\n",
    "\n",
    "test_f1 = f1_score(y_test, preds)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining XGBoost with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [500],\n",
    "              'learning_rate': [0.2, 0.1,0.07,0.05],\n",
    "              'max_depth': [2,3, 4],\n",
    "              'colsample_bytree': [0.6, 0.5],\n",
    "              'min_child_weight': [ 3,4]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the Gridsearch model\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = clf_xgb,\n",
    "    param_grid = param_dist, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    iid=False, \n",
    "    cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   21.7s finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs...\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.6, 0.5],\n",
       "                         'learning_rate': [0.2, 0.1, 0.07, 0.05],\n",
       "                         'max_depth': [2, 3, 4], 'min_child_weight': [3, 4],\n",
       "                         'n_estimators': [500]},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.fit(train[predictors],train[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.34786057, 0.37507501, 0.3756856 , 0.34901862, 0.41745634,\n",
       "        0.41916046, 0.27961993, 0.27762771, 0.35575542, 0.35303168,\n",
       "        0.40929294, 0.41331034, 0.2764811 , 0.30807476, 0.41693993,\n",
       "        0.35181518, 0.40841088, 0.40504489, 0.27486696, 0.26584086,\n",
       "        0.35028486, 0.34764643, 0.40646563, 0.41227722, 0.25473228,\n",
       "        0.28826385, 0.33623962, 0.32193899, 0.41889882, 0.38661242,\n",
       "        0.2697298 , 0.25462499, 0.3112052 , 0.31873283, 0.36489463,\n",
       "        0.38816481, 0.26515207, 0.25688982, 0.34065938, 0.33390441,\n",
       "        0.38174109, 0.39310498, 0.26125369, 0.26678123, 0.32311502,\n",
       "        0.32425609, 0.36853476, 0.33015356]),\n",
       " 'std_fit_time': array([0.02478168, 0.06346088, 0.01081046, 0.01089457, 0.01789348,\n",
       "        0.01711572, 0.00673385, 0.00671481, 0.01082664, 0.01090527,\n",
       "        0.00727946, 0.011792  , 0.01661891, 0.02054002, 0.0279796 ,\n",
       "        0.02508913, 0.0076741 , 0.00845195, 0.0079869 , 0.00377764,\n",
       "        0.00393959, 0.03048766, 0.02250196, 0.00903615, 0.01896656,\n",
       "        0.0500041 , 0.02039796, 0.0109285 , 0.01124718, 0.02783415,\n",
       "        0.00769054, 0.00403177, 0.01082167, 0.01173903, 0.01253181,\n",
       "        0.01498242, 0.01472468, 0.00515298, 0.01090251, 0.0087012 ,\n",
       "        0.00361551, 0.00803536, 0.02011187, 0.00397341, 0.01325533,\n",
       "        0.01493794, 0.00824225, 0.04431123]),\n",
       " 'mean_score_time': array([0.00987787, 0.00878782, 0.01186819, 0.01121945, 0.01170897,\n",
       "        0.01446924, 0.01503406, 0.00796676, 0.01187148, 0.01368184,\n",
       "        0.01295362, 0.0115787 , 0.01171379, 0.0109468 , 0.01234064,\n",
       "        0.01174841, 0.01370082, 0.01241393, 0.00837522, 0.0076128 ,\n",
       "        0.01519299, 0.01034541, 0.01282749, 0.01054311, 0.0078342 ,\n",
       "        0.0101799 , 0.01318994, 0.01200795, 0.01100879, 0.01323895,\n",
       "        0.01030226, 0.00955582, 0.01098933, 0.01139455, 0.01024613,\n",
       "        0.01119804, 0.0088975 , 0.00845523, 0.01059999, 0.01253505,\n",
       "        0.0128983 , 0.0114552 , 0.00995345, 0.00836754, 0.01144719,\n",
       "        0.01198816, 0.01202617, 0.00986705]),\n",
       " 'std_score_time': array([0.00287043, 0.00072531, 0.00193491, 0.00223451, 0.00214818,\n",
       "        0.0041284 , 0.00743796, 0.00064612, 0.00240122, 0.00489672,\n",
       "        0.00153737, 0.00092993, 0.00620852, 0.00430033, 0.00444965,\n",
       "        0.00247627, 0.00280692, 0.00201626, 0.00091529, 0.00079058,\n",
       "        0.00577084, 0.00159964, 0.0026668 , 0.00097784, 0.00055161,\n",
       "        0.00161569, 0.00426804, 0.0034867 , 0.00136752, 0.00275756,\n",
       "        0.00345474, 0.00352795, 0.00107109, 0.00192038, 0.00132449,\n",
       "        0.0014715 , 0.00266973, 0.00133677, 0.00071855, 0.00277151,\n",
       "        0.00161687, 0.00182941, 0.00282581, 0.00150975, 0.00313966,\n",
       "        0.0017265 , 0.00096475, 0.0020651 ]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.07, 0.07, 0.07, 0.07,\n",
       "                    0.07, 0.07, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[2, 2, 3, 3, 4, 4, 2, 2, 3, 3, 4, 4, 2, 2, 3, 3, 4, 4,\n",
       "                    2, 2, 3, 3, 4, 4, 2, 2, 3, 3, 4, 4, 2, 2, 3, 3, 4, 4,\n",
       "                    2, 2, 3, 3, 4, 4, 2, 2, 3, 3, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4,\n",
       "                    3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4,\n",
       "                    3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.2,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 2,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 3,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.05,\n",
       "   'max_depth': 4,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.86538462, 0.86538462, 0.8490566 , 0.85436893, 0.83809524,\n",
       "        0.85436893, 0.85714286, 0.85714286, 0.87378641, 0.8627451 ,\n",
       "        0.84615385, 0.84313725, 0.87378641, 0.84615385, 0.87378641,\n",
       "        0.87378641, 0.85148515, 0.82352941, 0.8627451 , 0.85148515,\n",
       "        0.87378641, 0.87378641, 0.8490566 , 0.85148515, 0.86538462,\n",
       "        0.88235294, 0.86538462, 0.86538462, 0.83495146, 0.84313725,\n",
       "        0.87378641, 0.85714286, 0.86538462, 0.87378641, 0.84313725,\n",
       "        0.83168317, 0.8627451 , 0.8627451 , 0.86538462, 0.87378641,\n",
       "        0.85436893, 0.85436893, 0.8627451 , 0.8627451 , 0.86538462,\n",
       "        0.87128713, 0.85714286, 0.87378641]),\n",
       " 'split1_test_score': array([0.72340426, 0.72164948, 0.74747475, 0.74747475, 0.75728155,\n",
       "        0.75728155, 0.70833333, 0.72916667, 0.7628866 , 0.73684211,\n",
       "        0.76767677, 0.72916667, 0.72340426, 0.72916667, 0.71428571,\n",
       "        0.74468085, 0.75510204, 0.74468085, 0.72340426, 0.72340426,\n",
       "        0.72164948, 0.72340426, 0.73469388, 0.70967742, 0.72164948,\n",
       "        0.73469388, 0.74226804, 0.72164948, 0.73786408, 0.72727273,\n",
       "        0.72916667, 0.72916667, 0.73469388, 0.73684211, 0.75      ,\n",
       "        0.72916667, 0.71428571, 0.72916667, 0.72164948, 0.73684211,\n",
       "        0.73469388, 0.75      , 0.74226804, 0.73684211, 0.71428571,\n",
       "        0.73684211, 0.70833333, 0.71578947]),\n",
       " 'split2_test_score': array([0.75471698, 0.74766355, 0.73394495, 0.72897196, 0.73394495,\n",
       "        0.72222222, 0.74285714, 0.73584906, 0.75728155, 0.73584906,\n",
       "        0.74074074, 0.73584906, 0.75728155, 0.75728155, 0.77227723,\n",
       "        0.74285714, 0.77669903, 0.74766355, 0.75728155, 0.75728155,\n",
       "        0.76470588, 0.75728155, 0.76470588, 0.74285714, 0.74766355,\n",
       "        0.72897196, 0.73584906, 0.71698113, 0.72727273, 0.74074074,\n",
       "        0.76470588, 0.73584906, 0.76923077, 0.74285714, 0.74074074,\n",
       "        0.74766355, 0.76470588, 0.75728155, 0.75728155, 0.74285714,\n",
       "        0.75728155, 0.74766355, 0.75728155, 0.75728155, 0.75      ,\n",
       "        0.75728155, 0.74509804, 0.74285714]),\n",
       " 'split3_test_score': array([0.78095238, 0.79245283, 0.78846154, 0.80769231, 0.78504673,\n",
       "        0.8       , 0.7962963 , 0.80373832, 0.78095238, 0.78095238,\n",
       "        0.78846154, 0.78846154, 0.80373832, 0.80373832, 0.80769231,\n",
       "        0.8       , 0.78846154, 0.7961165 , 0.80373832, 0.8       ,\n",
       "        0.80769231, 0.8       , 0.7961165 , 0.80769231, 0.78431373,\n",
       "        0.78095238, 0.80769231, 0.78431373, 0.80373832, 0.79245283,\n",
       "        0.79245283, 0.80373832, 0.7961165 , 0.78846154, 0.78846154,\n",
       "        0.8       , 0.79245283, 0.80373832, 0.8       , 0.80769231,\n",
       "        0.7961165 , 0.7961165 , 0.79245283, 0.78504673, 0.8       ,\n",
       "        0.80769231, 0.7961165 , 0.80769231]),\n",
       " 'split4_test_score': array([0.78      , 0.78      , 0.78      , 0.78787879, 0.79207921,\n",
       "        0.80392157, 0.76      , 0.75728155, 0.76767677, 0.78      ,\n",
       "        0.76767677, 0.78787879, 0.72727273, 0.75247525, 0.7628866 ,\n",
       "        0.75510204, 0.7628866 , 0.8       , 0.72      , 0.71428571,\n",
       "        0.75510204, 0.75510204, 0.73684211, 0.78787879, 0.77227723,\n",
       "        0.76470588, 0.78      , 0.7755102 , 0.78431373, 0.79207921,\n",
       "        0.73267327, 0.75728155, 0.7755102 , 0.74747475, 0.76767677,\n",
       "        0.78787879, 0.73786408, 0.74      , 0.7628866 , 0.74747475,\n",
       "        0.7628866 , 0.7628866 , 0.7254902 , 0.71428571, 0.74747475,\n",
       "        0.74      , 0.7628866 , 0.76767677]),\n",
       " 'mean_test_score': array([0.78089165, 0.7814301 , 0.77978757, 0.78527735, 0.78128954,\n",
       "        0.78755886, 0.77292593, 0.77663569, 0.78851674, 0.77927773,\n",
       "        0.78214193, 0.77689866, 0.77709665, 0.77776313, 0.78618565,\n",
       "        0.78328529, 0.78692687, 0.78239806, 0.77343384, 0.76929133,\n",
       "        0.78458722, 0.78191485, 0.77628299, 0.77991816, 0.77825772,\n",
       "        0.77833541, 0.7862388 , 0.77276783, 0.77762806, 0.77913655,\n",
       "        0.77855701, 0.77663569, 0.78818719, 0.77788439, 0.77800326,\n",
       "        0.77927843, 0.77441072, 0.77858633, 0.78144045, 0.78173054,\n",
       "        0.78106949, 0.78220712, 0.77604754, 0.77124024, 0.77542902,\n",
       "        0.78262062, 0.77391547, 0.78156042]),\n",
       " 'std_test_score': array([0.04718002, 0.04875614, 0.04004784, 0.04445712, 0.03514346,\n",
       "        0.04488139, 0.05075841, 0.04797374, 0.04334739, 0.046167  ,\n",
       "        0.03541187, 0.04148549, 0.05624344, 0.04188696, 0.05299494,\n",
       "        0.04977724, 0.03425052, 0.03104476, 0.05387744, 0.05093981,\n",
       "        0.05237584, 0.0519936 , 0.04268169, 0.04952553, 0.04858813,\n",
       "        0.05541406, 0.0474042 , 0.05374744, 0.04032183, 0.04148499,\n",
       "        0.05291183, 0.04797374, 0.04336797, 0.05127416, 0.03641738,\n",
       "        0.03677036, 0.05132901, 0.04919435, 0.04877281, 0.05262674,\n",
       "        0.04158462, 0.04001159, 0.04865154, 0.051353  , 0.0526542 ,\n",
       "        0.05107758, 0.05034438, 0.05514531]),\n",
       " 'rank_test_score': array([21, 18, 23,  7, 19,  3, 45, 37,  1, 25, 13, 36, 35, 33,  6,  9,  4,\n",
       "        11, 44, 48,  8, 14, 39, 22, 30, 29,  5, 46, 34, 26, 28, 37,  2, 32,\n",
       "        31, 24, 42, 27, 17, 15, 20, 12, 40, 47, 41, 10, 43, 16],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 3,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885167415464683"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.775785\n",
      "F1: 0.662162\n"
     ]
    }
   ],
   "source": [
    "preds = gsearch1.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "test_f1 = f1_score(y_test, preds)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb53537f910>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot feature importance\n",
    "plot_importance(alg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fare': 231,\n",
       " 'Parch': 91,\n",
       " 'male': 42,\n",
       " 'Pclass': 81,\n",
       " 'SibSp': 86,\n",
       " 'S': 43,\n",
       " 'Q': 37,\n",
       " 'youngin': 27,\n",
       " 'Age': 150}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.get_booster().get_fscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle list object\n",
    " \n",
    "model_pickle_path = 'xg_boost_model.pkl'\n",
    "\n",
    "# Create an variable to pickle and open it in write mode\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(gsearch1.best_estimator_, model_pickle)\n",
    "model_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XGboost model ::  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=3, missing=nan, n_estimators=500, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Loading the saved XGboost model pickle\n",
    "xgboost_model_pkl = open(model_pickle_path, 'rb')\n",
    "xgboost_model = pickle.load(xgboost_model_pkl)\n",
    "print(\"Loaded XGboost model :: \", xgboost_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 5), (9, 6), (9, 7), (10, 5), (10, 6), (10, 7), (11, 5), (11, 6), (11, 7)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
